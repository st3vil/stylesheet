MetaphysicsMetaphysics: |
    the nest is pretty cold
    women in charge of immortality
     keeps being implied that they dont have the steez that they do
    Ive got a bunch of parts, most go like ->
    ITS stuff you will slide off into other things from
    its already sitting there in the universe, we just need to find the center of it so we can make efficient systematising (everything trans fats) trips around it.
    
    
    
YouToo: |
    $s ||= 'PLjMNWea6sX7L-qIbKVzgKmoYdWuqsh2yV';
    $s = <<''.$s unless $s =~ /^http/;
        https://www.youtube.com/playlist?list=
    #use WWW::Mechanize;
    #my $m = new WWW::Mechanize;
    #$m->get($url);
    my @h = read_file("yout\.html");
    my @l;
    my $e = 0;
    while (@h) {
        my $v = $l[-1] if @l;
        for (shift @h) {
        if ($e == 0) {
            /class=.pl-video-title-link/ || next;
            my ($yt) = /href=..watch\?v=([-\w]+)/;
            (my $t = shift @h) =~ s/^\s+|\s+$//sg;
            push @l, {t=>$t,sc=>{yt=>$yt}};
            $e = 1;
        }
        elsif ($e == 1) {
            /div class="timestamp".+>(\d+:\d+)<\/span>/ || next;
            v.sc.duration = $1;
            my ($ms,$ss) = split ':', $1;
            v.sc.secs = $ms * 60 + $ss;
            $e = 0;
        }
        }
    }
    say "Done: ".wdump 4, \@l;
    
    
    
    
    
    #
    
Zo: | # tumblr suction
    use WWW::Mechanize;
    my $m = new WWW::Mechanize;
    use YAML::Syck;
    
    my $url = "http://st33v\.tumblr\.com/";
    my @posts;
    if (0) {
    my $page = 1;
    my $last;
    while ($posts[-1] !~ /66098836$/) {
        say "getting page $page";
        my $url = "$url".($page>1?"page/$page":"");
        $m->get($url);
            my $next = $page + 1;
        push @posts, $m->content =~ /<a href="([^"]+\/post\/\d+)"/sg;
        saybl "Page $page: ".wdump \@posts;
        #last unless $m->content =~ m{<a href="(/page/$next)">};
        $page++> 200 && last;
        last if $last eq $posts[-1];
        $last = $posts[-1];
        DumpFile("posts\.yml", \@posts);
    }
    DumpFile("posts\.yml", \@posts);
    
    @posts = @{LoadFile("posts\.yml")};
    my $i = 1;
    my @photos = 1;
    my $piles = [[]];
    my $pilof = 200;
    my $ii = 0;
    for my $post (@posts) {
        $i++;
        $m->get($post);
        push @{$piles->[-1]}, $m->content =~ m{"([^"]+?jpg)"}smg;
        if (@{$piles->[-1]} >= $pilof) {
            push @$piles, [];
            say "FI ".$i;
            DumpFile("pILEs",$piles);
        }
    }
    }
    my $piles = LoadFile("pILEs");
    my $i = 0;
    my @all;
    for (@$piles) {
        s/\\\//\//g for @$_;
        @$_ = uniq @$_;
        push @all, @$_;
    }
    my $tw;
    for (@all) {
        my $st = /1280.jpg/ ? 'ii' : 'oo';
        my $sec = $i++ % 4;
        /http:\/\/(\d+)\.media\.tumblr/ || next;
        $sec = $1;
        push @{$tw->{$st}->{$sec}||=[]}, $_;
    }
    my $fl;
    while (my ($k,$v) = each %$tw) {
        while (my ($s,$e) = each %$v) {
            push @{$fl->{"st33v\.$k\.$s\.c"}||=[]}, @$e;
        }
    }
    while (my ($k,$v) = each %$fl) {
        write_file("n/W/$k", join "\n", shuffle @$v);
        say "$k";
    }
    exit;
Zoing: |
    my @l = shuffle map{chomp;$_} `cd n; find i th -type f`;
    say "Fot: ".join "\n",@l;
    for (1..3) {
        @l = shuffle @l;
        G&wraf,"n/W/Earlie\.1$_\.c",\@l;
    }
Zwah: |
    my @f = map { map{chomp;$_} `cat n/W/EarlyCoast.${_}.c` } 20..29;
    for (@f) {
        my $d = $_;
        $d =~ s/\/[^\/]+$//sg;
        $d = "n/$d";
        `mkdir -p $d` if !-d $d;
        `cp public/$_ $d`;
        saybl "$d\n$_";
    }
        
    
Zos: |
    my @in = `cat n/W/st33v\.ii\.41\.c`;
    my $i = 0;
    `cd n/i/41; wget $_` for @in;
Zso: |
    my $pi = {};
    my $i = 0;
    for (`cat n/W/st33v\.3\.c`) {
        my $wi = $i++ % 5;
        push @{$pi->{$wi}||=[]}, $_;
    }
    write_file("n/W/st33v\.b$_\.c", @{$pi.>$_ }) for keys %$pi;

